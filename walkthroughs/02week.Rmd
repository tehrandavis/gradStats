---
editor_options:
  chunk_output_type: console
output:
  html_document:
    df_print: paged
  pdf_document: default
---
# Measures of distribution, central tendency, PLOTS... oh my!

We covered a lot of ground this week talking about measures of central tendency and introducing ourselves to distributions. When you get a chance be sure to check out some of the in-class workshopping code and examples on RStudio.cloud. These will help you remember what we did in the workshop and you can compare them to your source and output.

This week I want to expand upon a few things that were touched upon in the workshop and in lecture. This one might be a little lengthly, but it should serve to supplement your assigned readings and help you a little with the home work. Before jumping in, let's install and load the necessary packages in R. This week we will make use of `psych` and several of the core packages of the `tidyverse`. We'll also be using `pander()`

Using the `cheat code` from last week's **Level-up**:

```{r}
# 1. check to see if pacman is on your computer and if not, let's install it:
if (!require("pacman")) install.packages("pacman",repos="http://cran.us.r-project.org")

# 2. install all other packages that we will be using:
pacman::p_load(psych, tidyverse, pander)
```

Throughout this walkthrough we'll use data from an example provided in the Howell textbook (Table 2.1). Let's start by reading that data into `R`. Since the data was reaction time data, let's just name it `RTData`. Note that I'm just using the code generated by the GUI method of data loading (see Week 1):

```{r}
# importing data:
RTData <- readr::read_csv(file = "datasets/Tab2-1.dat")
```

Invoking `class(RTData)` tells us that RTData is a data frame. Invoking `names(RTData)` provides us with the header names (but you already knew that):

```{r}
class(RTData)
names(RTData)
```

Building from last week's homework assignment, we can call individual columns within the data frame using the `$` operator:

```{r}
# column of Trial(s):
RTData$Trial

# column of RxTime (reaction time)
RTData$RxTime
```

## Getting measures of central tendency

We can use simple functions to get the mean, median, and standard deviation of a vector:

```{r}
mean(RTData$RxTime) #mean
median(RTData$RxTime) #median
sd(RTData$RxTime) #std. dev.
```

However, most of the data that we deal with comes in the for of data frames (e.g., `tibbles`. In this week's workshop, we touched upon using `psych::describe()` to generate summary stats of all data in a data frame:
```{r}
psych::describe(RTData)
```

This provides info related to the:

1. item name
2. item number
3. number of valid cases
4. mean
5. standard deviation
6. trimmed mean (with trim defaulting to .1)
7. median (standard or interpolated)
8. mad: median absolute deviation (see Leys et al, 2013)
9. minimum value
10. maximum value
11. skew
12. kurtosis
13. standard error

### turning numeric data into categorical

As you can see we get a mean, sd, median, etc for `NStim`, **BUT SHOULD WE?** The number of stimuli is not numerical properly... but instead represent experimental categories. The same can be said for the `YesNo` data. We need to tell `R` that these data are categories, or _factors_ and not continuous numbers. To do so we can call on the `factor()` function as below.

```{r}
# convert a numeric to a categorical (i.e., make a factor)
factor(RTData$NStim)
```

When you run the line above you'll note at the end of the output it mentions `Levels: 1 3 5`. This is telling you that in this vector, there are three levels, or conditions in this factor- number of stimuli = 1; number of stimuli = 3; number of stimuli = 5. To connect this factorized vector to your original data set, you can either create a new column in the data set or overwrite the original `NStim` column that you are replacing. For beginners, I would recommend adding a new column. To do this, let's take advantage of some of those fancy `tidyverse` / `dplyr` skills you picked up from DataCamp:

```{r}
# 1. create a new vector attached to the original data frame
#    using the dplyr::mutate function:

RTData <- RTData %>% dplyr::mutate(categoricalNStim = factor(NStim))
psych::describe(RTData) 
```
The asterisk next to `categoricalNStim` lets you know it's categorical. 

Note that you could have just strung several pipes together and obviated the need to save to an object. This is useful if you just want to print the output and don't need to save it for later use.

```{r}
RTData %>% 
  dplyr::mutate(categoricalNStim = factor(NStim)) %>%
  psych::describe() 
```

Now that I look at it, `YesNo` is categorical as well. This can be accomplished by just adding another argument to `mutate`:

```{r}
RTData %>% 
  dplyr::mutate(categoricalNStim = factor(NStim),
                categoricalYesNo = factor(YesNo)) %>%
  psych::describe() 
```

### Getting summary stats by groups or conditions

You may also get summary statistics subsetted for individual `group`s. In this case the `NStim` column represents experimental conditions (num. of stimuli = 1, num. of stimuli = 3, num. of stimuli = 5). To take a look at the summary stat by condition we use the `psych::describeBy()` function:

```{r}
psych::describeBy(RTData,group = RTData$NStim)
```

## Creating a table of summary stats

I personally am not a big fan of presenting / publishing data in tables. My feeling is that all things being equal, an good plot is typically the most effective way to present data. BUT, I recognize that there are times that call for us to present our data in tables.

One downside is that by default, `psych::describe()` doesn't give us nice pretty (APA-esqu) tables, and putting this ouput into a cleaner format requires a little work. In order to do so, we can leverage some of the functions from the `tidyverse`. How you go about constructing a cleaner table depends in large part on the content. For example, if you just wanted to convey the number of observations, mean, and std. dev, then it might be best to construct a summary table using `dplyr::summarize()`. For example a summary of `RxTime`:

```{r}
RTData %>% dplyr::summarise("count" = n(),
                            "mean" = mean(RxTime),
                            "sd" = sd(RxTime)
                            ) %>% 
  pander(caption = "Table X. Summary statistics for reaction time")
```

`pander()` allows us to put the table in a neat (publication friendly) format, including adding a `caption` or title.

We can also create a simple table by `group` by using `dplyr::group_by()`

```{r}
RTData %>% 
  dplyr::group_by(categoricalNStim) %>% 
  dplyr::summarise("count" = n(),
                   "mean" = mean(RxTime),
                   "sd" = sd(RxTime)
                   ) %>% 
  pander(caption = "Table X. Summary statistics for reaction time by group")
```

There is still some work to be done if you were sending a table like this to publication. We'll table more about that in this week's Level Up. For our purposes right now, however, this will do.

## Creating a figure plot of your data

As I mentioned above, I'm a firm believer that given the choice of creating a table or producing a plot, choose makeing the plot unless there are other important factors that make the table more desireable. There are any number of plots that you make use in your analyses: scatterplots, bar plots (although there's a bit of a backlash on barplots right now), histograms, boxplots, violin plots, heatmaps, rug plots, and the list goes on and on. What type of plot you choose to make should depend on what info you are attempting to stress and convey to your audience (including you). We'll encounter most of these plots throughout the semester. For this walkthrough we'll focus on histograms and boxplots.

### Plotting the distribution with a histogram

Histograms are best when you are trying to convery information about the entire distrubution of your data, for example the frequency of observed values in your data set.

#### Using `hist()`
In class we used the `hist()` call on a vector of scores to produce a quick and dirty histogram. For example to produce a histogram of `RxTime` from our `RTData` dataset we can:
```{r}
hist(RTData$RxTime) # R auto-selects number of bins
hist(RTData$RxTime, breaks = 5) # create 5 bins 
```

The second line above forces `R` to create 5 bins. If you recall from Howell, one rule of thumb for the number of bins (there are many) is to use the square root of the number of observations. To do that here we can first use the `length()` function to get the number of observations (i.e., the length of the `RTData$RxTime` vector of scores):

```{r}
length(RTData$RxTime) # length of vector
```

Note that length works on vectors, but not on entire data frames (multiple columns of data). Vectors are 1 dinmensional... think of a line of data. Data sets (or data frames) are multidimensional (colmuns and rows of data). Since each column contains our variables, the number of obervations corresponds to the number of rows in the data set. So, to get the "length" you just need to count the number of rows:

```{r}
nrow(RTData) # number of rows in the data set (each row corresponds to an observation)
```

For now, either of these will work for getting your `N`. Moving forward we will encounter other methods of getting data counts as well. But for now this works.

Returning to the 'optimal' number of bins, be can now put together the following:
```{r}
N <- length(RTData$RxTime)
hist(RTData$RxTime, breaks = sqrt(N)) # create square root of N bins 
```

#### Plotting a histogram with `ggplot()` (normal curve overlay)

*This section assumes you have completed this week's DataCamp assignment that includes a wonderful introduction to plotting with `ggplot()`. If you have yet to do so, please go there first. That said this section represents a brief review on how to create a ggplot in general*

Now let's try fitting a normal curve to our histogram. For this we are going to move into more complex ways of plotting data using `ggplot2` from the `tidyverse`. You've been introduced to the `tidyverse` in this week's DataCamp homework assignments. The Field text, Ch. 4 also covers `ggplot()` extensively. Be sure to check out some of the other `ggplot()` resources listed in this week's module on Canvas. Once you get the hang of things you can create just about any plot your heart desires using `ggplot()` in conjunction with a variety of add-ons that people have created. One of my favorite add-ons is `cowplot()`. I'll show some examples incoporating `cowplot()` in a future Level-up, but if you want to jump ahead check it out [here](https://wilkelab.org/cowplot/).

First let's use `ggplot()` to create a histogram. To get a feel for each step, **run through this code line by line in RStudio**: 

```{r}
# load in tidyverse if you haven't already
pacman::p_load(tidyverse)

# Step 1: identify data and grouping parameters
histPlot1 <- ggplot2::ggplot(data = RTData, aes(x=RxTime))
histPlot1 # note that this produces a blank slate but the parameters are locked in.

# take histPlot 1 (blank plot) and paint a layer on top of it
# tell ggplot what to do (this is where you actually build the graphics):

# take histPlot 1's parameters and...
histPlot2 <- histPlot1 + 
  # build a histogram 
  geom_histogram(binwidth = 5, # bins are 5 units wide
                color = "orange", # what color is the outline of bars
                fill = "green") # what color to fill the bars with
histPlot2 # show the frequency plot
```

I intentially made a hideous looking plot above to show you what the additional arguments do. Also note that with `ggplot()` you modify the width of the bin `binwidth` rather than the number of bins, or `breaks` as in `hist()`. Let's turn this into something a little more pleasing to the eyes:

```{r}
histPlot2 <- histPlot1 + 
  geom_histogram(binwidth = 5, 
                color = "black", # what color is the outline of bars
                fill = "white") # what color to fill the bars with
histPlot2
```

Okay, now to add a curve representing the normal distribution. One important thing to note is that the histogram that is ultimately produced here has probability density (think like % of scores) on the y-axis instead of frequency (# of scores). So we'll need to convert our frequency plot to a probability density plot. Fortunately this is just one line of code:

```{r}
# take histPlot 1 (blank plot) and paint a layer on top of it
# tell ggplot what to do (this is where you actually build the graphics):
histPlot3 <- histPlot1 + 
  geom_histogram(binwidth = 5, 
                 color = "black",
                 fill = "white",
                 aes(y=..density..)# converst to a prob density plot
  )
histPlot3 
```

notice that `histPlot3` is a density plot rather frequency plot from above. Now to add the normal curve:

```{r}
# add a normal curve to density plot:
histPlot4 <- histPlot3 + 
  stat_function(fun = dnorm, # generate theoretical norm data
                color = "red", # color the line red
                args=list(
                  mean = mean(RTData$RxTime,na.rm = T), # build around mean
                  sd = sd(RTData$RxTime,na.rm = T) # st dev parameter
                )
  )

histPlot4
```

Howell also mentions a better alternative to the normal curve, a kernel density plot. To fit a kernel density plot to our histogram we can invoke:

Howell also mentions a better alternative to the normal curve, a kernel density plot. To fit a kernel density plot to our histogram (histPlot3) we can invoke:

```{r}
# hisPlot 3 was the base histogram without curve
histPlot3 + geom_density()
```

and let's make the x-axis label a little more transparent with `xlab()`
```{r}
histPlot3 + geom_density() + xlab("Reaction time (ms)")
```

Keep in mind, that although we walked-through making `histPlot1`, then `histPlot2`, `histPlot3`, `histPlot4`, we could have accomplished all of this with a single assign:

```{r}
histPlot <- ggplot2::ggplot(data = RTData, aes(x=RxTime)) +
  geom_histogram(binwidth = 5, 
                color = "black", 
                fill = "white",
                aes(y=..density..))  +
  stat_function(fun = dnorm, # generate theoretical norm data
                color = "red", # color the line red
                args=list(
                  mean = mean(RTData$RxTime,na.rm = T), # build around mean
                  sd = sd(RTData$RxTime,na.rm = T) # st dev parameter
                )
  )

histPlot
```

**Q: Any guesses on how to change the y-axis label to "Percent of scores"?** Hint, check the workshop code.

### Plotting your data in a boxplot:

Let's recreate the boxplot from Howell, Figure 2.15 using `ggplot()`

Now let's create a few boxplots of `RxTime`. First the entire dataset, indifferent to the 3 different categories of `NStim`:

```{r}
# Set the parameters (data and axes)
ggplot2::ggplot(data = RTData, aes(y=RxTime)) + 
  geom_boxplot() # tell R to make it a boxplot
```

Note that the `x-axis` in this plot is meaningless. We can remove it if we want:

```{r}
# Set the parameters (data and axes)
ggplot2::ggplot(data = RTData, aes(y=RxTime)) + 
  geom_boxplot() +    # tell R to make it a boxplot
  theme(axis.text.x=element_blank(),
        axis.ticks.x = element_blank()
        )
```


Now let's take a look at the data that will be boxplotted as a function of `categoricalNStim` groups. Here I want to note that `psych::describeBy` has an additional argument to display the quantiles:

```{r}
psych::describeBy(RTData,group = RTData$categoricalNStim,quant=c(.25,.75))
```

To plot this we need to tell `R` to put different distributions at different points along the `x-axis`

```{r}
ggplot2::ggplot(data = RTData, aes(y=RxTime, x = categoricalNStim)) + 
  geom_boxplot()
```

Before leaving I want to show what would've happended in the latter case if we didn't correct `NStim` and left it as a numeric variable rather than converting to a categorical:

```{r}
# creating the boxplot using exact code from chunk above:
ggplot2::ggplot(data = RTData, aes(y=RxTime, x = NStim)) + 
  geom_boxplot()
```

Since `R` treats the categorical variable as a numeric, all of the data gets lumped together at the mean value of `NStim` even though we explicitly tried to group our data by this variable. Remember, you need to be careful with having categorical data coded as numbers!


### Assessing the data for normality

As mentioned in class, one of the key underlying assumptions of our inferential stat is that the data being analyzed is normally distributed. Let's return to our `RTData`, including a column for `categoricalNStim`. Notice how I'm flexing my ninja skills by piping this all together:

```{r}
RTData <- readr::read_csv(file = "datasets/Tab2-1.dat") %>%
  dplyr::mutate(categoricalNStim = factor(NStim),
                categoricalYesNo = factor(YesNo)
                )
RTData
```

While leaving the number codes (1,3,5) for `categoricalNStim` is reasonable (after all it is conveying a number), number coding for `YesNo` might be a bit confusing (or at least we'd always have to remember the key). We can map those numbers onto "Yes" and "No" quite easily using `recode_factor()` in our `mutate`:

```{r}
RTData <- readr::read_csv(file = "datasets/Tab2-1.dat") %>%
  dplyr::mutate(categoricalNStim = factor(NStim),
                categoricalYesNo = recode_factor(YesNo,"1"="Yes","2"="No")
                )
RTData
```

#### Step 1: First take a look at the histogram

Let's plot `RxTime` with a normal curve overlayed (see above):
```{r}
# load in tidyverse if you haven't already
pacman::p_load(tidyverse)

# identify data and grouping parameters:
ggplot2::ggplot(data = RTData, aes(x=RxTime)) +
  geom_histogram(binwidth = 5, 
                  color = "black",
                  fill = "white",
                  aes(y=..density..)) + 
  stat_function(fun = dnorm, 
                 color = "red",
                 args=list(mean = mean(RTData$RxTime),
                 sd = sd(RTData$RxTime)))
```

Eyeballing this histogram, the jury is still out. While the distribution doesn't seem terribly skewed (shifted to the left or right of our idealized curve) the distribution does look a little "pointy".

#### Step 2: Get measures of skew and kurtosis

We can get a further assessment of skew and kurtosis using `psych::describe()`:
```{r}
psych::describe(RTData)
```

As conveyed here, our values for skew falls within the ideal range, but kurtosis is borderline

#### Step 3: Q-Q Plots
Another method of assessing normalitly is by using a quantile-quantile, or Q-Q plot. A Q-Q plot is the plot of the sample quantiles from your data against a theoretical normal distribution. Q-Q plots typically use a straight line `y=x` as an assessment device where any deviation away from the straight line indicates deviation from normality.

You can make a qq-plot using the `ggplot()` framework:
```{r}
ggplot(RTData, aes(sample=RxTime)) + 
  stat_qq() + stat_qq_line()
```

Using `ggplot()` is especially useful is you elect to look at subsets of a grand distribution. For example, we can look at the qq-plot for each `categoricalNStim` by just adding `group` to our initial call. Notice that I've also assigned color `col` to each group for ease of reading:
```{r}
ggplot(RTData, aes(sample=RxTime, group = categoricalNStim, col=categoricalNStim)) + 
  stat_qq() + stat_qq_line()
```


## Level-up: advanced working with subsets and plots

Your homework this week asks you to subset your data by condition and create a plot for each resulting condition (or group). For example in our `RTData` there are 3 conditions by `categoricalNStim`: 1, 3, and 5. We've already shown that we can get summary data for each `categoricalNStim` condition by using `psych::describeBy()`. Note that here I'm calling the `RxTime` vector by itself rather than the entire `RTData` data frame, since it really the only variable that I care about for my descriptive stats:

```{r}
psych::describeBy(RTData$RxTime,group = RTData$categoricalNStim)
```

The `psych::describeBy` function is nice in that it's actually a two-for-one, it performs a subset and then it calculates a number of values for use based on that subset. A longer, but more precise way of doing this would be to combine the `dplyr::group_by()` function with `dplyr::summarise()` to create a table containing our desired values. For example I can create a summary table containing count `n()`, average `mean()`, and standard deviation`sd()` of `RxTime` for each category using the following:

```{r}
RTData %>% 
  dplyr::group_by(categoricalNStim) %>% 
  dplyr::summarise("count" = n(),
                   "mean" = mean(RxTime),
                   "stdev" = sd(RxTime)
                   )
```

Compared to `psych::describeBy()` this method is slighlty limited. While you can get the range and quartile info (see [here](https://dplyr.tidyverse.org/reference/summarise.html) for useful functions you can add, and try adding the minimum and maximum values), info about skew and kurtosis are trickier to get. That said, generating summary tables like this may come to be useful to us in the not too distant future. For now, let's keep this in the back of our minds.

In the meantime, how would we subset and summarize by `YesNo`? Go ahead I'll wait.

Now that you've done that, one last thing. We can subset by multiple conditions. For example in this data, categorical conditions can be broken down by both `YesNo` and `NStim`, resulting in 6 total `YesNo_Nstim` categories: Yes_1, Yes_3, Yes_5, No_1, No_3, No_5. To get our summary stats we can either use `psych::describeBy()`:

```{r}
psych::describeBy(RTData$RxTime,group = interaction(RTData$categoricalNStim, RTData$categoricalYesNo))
```

where `interaction()` simply tells `R` that these categories are being crossed with one another. We can also do this the long way:

```{r}
RTData %>% 
  dplyr::group_by(categoricalNStim,
                  categoricalYesNo) %>% 
  dplyr::summarise("count" = n(),
                   "mean" = mean(RxTime),
                   "stdev" = sd(RxTime)
                   )
```

### Plotting your data, subsets and all

There are a number of ways in which we can plot the data by category/group. Which we choose depends on how you want to convey the info. At the very least, we typically want to differentiate by categories in our plot(s). To accomplish this we can use `group` when we want to display multiple groups on a single plot, or `facet_wrap` when we want to have individual plots for each group. For example, focusing on differences by `NStim`

#### histogram same axis

Here I'm showing the distribution of each group on the same axis. Since I am overlaying the histograms on top of one another, a good rule of thumb is to add transparency to the fill
```{r}
ggplot(data = RTData, mapping = aes(x = RxTime, group=categoricalNStim)) +
  geom_histogram(binwidth = 5, 
                 color = "black",
                 aes(fill=categoricalNStim), # each group fill is a different color
                 alpha = .7 # make the fill semitransparent
                 )
```

Honestly, this sort of plot is often not practical, but I wanted to show you haw you might do it. A better alternative would be putting each distribution on different axes like below.

#### histogram different axes

To spead out data out among multiple plots is quite easy using `ggplot()`. You simply make a decision on how you want to subset your data plots and then add `facet_wrap()` to your call. So to plot each group `categoricalNStim` on a seperate plot:

```{r}
ggplot(data = RTData, mapping = aes(x = RxTime)) +
  geom_histogram(binwidth = 5, 
                 color = "black") +
  facet_wrap(facets = ~categoricalNStim, ncol = 3) #ncol = number of columns
# try facet_wrap() with nrow=3
```

#### If we so choose we can even do interactions...

For example, to create histogram plots of each `YesNo_NStim` category we simply call both in `facet_wrap()` along with the `*` operator (interaction = multiplication):

```{r}
ggplot(data = RTData, mapping = aes(x = RxTime)) +
  geom_histogram(binwidth = 5, 
                 color = "black") +
  facet_wrap(facets = ~categoricalYesNo*categoricalNStim, ncol = 3)
```

#### and boxplots

Everything we've done about we can do with any kind of plot. For example, boxplots with interactions between `categoricalNStim` and `categoricalYesNo`:

*Same axes with interactions:*
Here we differentiate `NStim` along the x-axis and `YesNo` by `fill` color. Note I also beed to tell `R` that I'm grouping by the `interaction` between the two variables.

```{r}
# unpacked for easier reading:
ggplot(data = RTData, 
       mapping = aes(x= categoricalNStim, 
                     y = RxTime,
                     group=interaction(categoricalNStim,categoricalYesNo)
                     )
       ) +
  geom_boxplot(aes(fill=categoricalYesNo))
```

*Different axes with interactions*
```{r}
ggplot(data = RTData, mapping = aes(y = RxTime)) +
  geom_boxplot() +
  facet_wrap(facets = ~categoricalYesNo*categoricalNStim, ncol = 3)
```

OK. I think that's enough for this wrap-up. Be sure to review the content posted on Canvas and check-out the `Shiny` app "Means and other models"